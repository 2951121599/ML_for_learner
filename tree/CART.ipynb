{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习实战中的代码\n",
    "## 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.datasets import load_boston\n",
    "# data=load_boston()\n",
    "# X,Y=data.data,data.target\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)\n",
    "\n",
    "# print(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型基本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def SplitData(data,f_idx,val):\n",
    "#     '''\n",
    "#     data: 待分割数据\n",
    "#     f_idx: 特征idx\n",
    "#     val: 该特征下的划分值\n",
    "#     '''\n",
    "#     data_left=data[data[:,f_idx]<=val]\n",
    "#     data_right=data[data[:,f_idx]>val]\n",
    "#     return data_left,data_right\n",
    "\n",
    "# # data=np.c_[X_train,Y_train]\n",
    "# # SplitData(data,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def regLeaf(data):\n",
    "#     return np.mean(data[:,-1])    # 返回数据中目标值的均值\n",
    "\n",
    "# def regErr(data):\n",
    "#     return np.var(data[:,-1])*len(data)    # 返回数据中目标的总方差\n",
    "\n",
    "# def creatTree(data,leafType=regLeaf,errType=regErr,param=(1,4)):\n",
    "#     '''\n",
    "#     leafType: 创建叶节点的函数名\n",
    "#     errType: 损失函数名\n",
    "#     '''\n",
    "#     cut_f,cut_val=test(data,leafType,errType,param)    # 寻找最佳特征与特征值\n",
    "    \n",
    "#     if not cut_f:\n",
    "#         return cut_val\n",
    "    \n",
    "#     tree={}\n",
    "#     tree['spInd']=cut_f\n",
    "#     tree['spVal']=cut_val\n",
    "    \n",
    "#     data_left,data_right=SplitData(data,cut_f,cut_val)    # 切分数据\n",
    "#     tree['left']=creatTree(data_left,leafType,errType,param)\n",
    "#     tree['right']=creatTree(data_right,leafType,errType,param)\n",
    "    \n",
    "#     return tree\n",
    "\n",
    "# def test(data,leafType=regLeaf,errType=regErr,param=(1,4)):\n",
    "#     '''\n",
    "    \n",
    "#     '''\n",
    "#     tol_S,tol_N=param[0],param[1]\n",
    "    \n",
    "#     if len(np.unique(data[:,-1]))==1:    # 目标值纯净\n",
    "#         return None,leafType(data)    # 根据数据制造一个叶节点返回\n",
    "    \n",
    "#     n_sample,n_feature=data.shape\n",
    "#     S_before=errType(data)    # 目标值的总方差\n",
    "#     best_S=np.inf;best_idx=0;best_val=0\n",
    "    \n",
    "#     # 遍历所有特征与所有独特值\n",
    "#     for f_idx in range(n_feature-1):    # 目标值不参与test\n",
    "#         for val in np.unique(data[:,f_idx]):\n",
    "#             data_left,data_right=SplitData(data,f_idx,val)\n",
    "            \n",
    "#             # 如果分裂后某一分支的数据量小于阈值则放弃分裂\n",
    "#             if len(data_left)<tol_N or len(data_right)<tol_N:\n",
    "#                 continue\n",
    "            \n",
    "#             S_after=errType(data_left)+errType(data_right)\n",
    "#             if S_after<best_S:\n",
    "#                 best_idx,best_val=f_idx,val\n",
    "#                 best_S=S_after\n",
    "            \n",
    "#             if S_before-best_S<tol_S:    # 如果分裂后的增益小于阈值则停止分裂\n",
    "#                 return None,leafType(data)\n",
    "            \n",
    "#     data_left,data_right=SplitData(data,best_idx,best_val)\n",
    "#     if len(data_left)<tol_N or len(data_right)<tol_N:\n",
    "#         return None,leafType(data)\n",
    "    \n",
    "#     return best_idx,best_val\n",
    "\n",
    "# # print(creatTree(np.c_[X_train,Y_train]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自己代码\n",
    "## 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13) (102, 13) (404,) (102,)\n",
      "(404, 14) (102, 14)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "data=load_boston()\n",
    "X,Y=data.data,data.target\n",
    "del data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)\n",
    "\n",
    "print(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)\n",
    "\n",
    "training_data=np.c_[X_train,Y_train]\n",
    "testing_data=np.c_[X_test,Y_test]\n",
    "\n",
    "print(training_data.shape,testing_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型基础\n",
    "对于CART用做回归时，分裂的依据有很多的可选方法，这里使用MSE作为分裂依据。注意这里的MSE跟模型评估时的MSE不同，这里的MSE计算方式为：\n",
    "$$\n",
    "H(X_{m})=\\frac{1}{N_{m}}\\sum\\limits_{i{\\in}N_{m}}(y_{i}-\\bar{y}_{m})^{2}\n",
    "$$\n",
    "其中$\\bar{y}_{m}$为第$m$个叶节点中所有训练样本的目标值均值，详见[这里](https://scikit-learn.org/stable/modules/tree.html#regression-criteria)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(data,y_idx=-1):\n",
    "    '''\n",
    "    返回数据集目标值的MSE\n",
    "    '''\n",
    "    N=len(data)\n",
    "    mean=np.mean(data[:,y_idx])\n",
    "    return np.sum(np.square(data[:,y_idx]-mean))/N\n",
    "\n",
    "# MSE(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义一个在指定特征与特征值下将数据集二分的函数，这里将小于等于分割值的数据集放入左分支，大于分割值的数据集放入右分支。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BinSplitData(data,f_idx,f_val):\n",
    "    '''\n",
    "    以指定特征与特征值二分数据集\n",
    "    '''\n",
    "    data_left=data[data[:,f_idx]<=f_val]\n",
    "    data_right=data[data[:,f_idx]>f_val]\n",
    "    return data_left,data_right\n",
    "\n",
    "# SplitData(training_data,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分割函数与分割指标计算函数都有了，接下来就可以在数据集中迭代寻找最佳分割特征与特征值了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test(data,criteria='mse',min_samples_split=5,min_samples_leaf=5,min_impurity_decrease=0.0):\n",
    "    '''\n",
    "    对数据做test，找到最佳分割特征与特征值\n",
    "    return: best_f_idx, best_f_val，前者为空时代表叶节点，两者都为空时说明无法分裂\n",
    "    min_samples_split: 分裂所需的最小样本数，大于1\n",
    "    min_samples_leaf: 叶子节点的最小样本数，大于0\n",
    "    min_impurity_decrease: 分裂需要满足的最小增益\n",
    "    '''\n",
    "    n_sample,n_feature=data.shape\n",
    "    \n",
    "    if n_sample<min_samples_split:    # 数据量小于阈值则直接返回叶节点\n",
    "        return None,np.mean(data[:,-1])\n",
    "    \n",
    "    MSE_before=MSE(data)    # 分裂前的MSE\n",
    "    best_gain=0\n",
    "    best_f_idx=None\n",
    "    best_f_val=np.mean(data[:,-1])    # 默认分割值设为目标均值，当找不到分割点时返回该值作为叶节点\n",
    "    \n",
    "    # 遍历所有特征与特征值\n",
    "    for f_idx in range(n_feature-1):\n",
    "        for f_val in np.unique(data[:,f_idx]):\n",
    "            data_left,data_right=BinSplitData(data,f_idx,f_val)    # 二分数据\n",
    "            \n",
    "            # 分割后的分支样本数小于阈值则放弃分裂\n",
    "            if len(data_left)<min_samples_leaf or len(data_right)<min_samples_leaf:\n",
    "                continue\n",
    "                \n",
    "            # 分割后的加权MSE\n",
    "            MSE_after=len(data_left)/n_sample*MSE(data_left)+len(data_right)/n_sample*MSE(data_right)\n",
    "            gain=MSE_before-MSE_after    # MSE的减小量为增益\n",
    "            \n",
    "            # 分裂后的增益小于阈值或小于目前最大增益则放弃分裂\n",
    "            if gain<min_impurity_decrease or gain<best_gain:\n",
    "                continue\n",
    "            else:\n",
    "                # 否则更新最大增益\n",
    "                best_gain=gain\n",
    "                best_f_idx,best_f_val=f_idx,f_val\n",
    "    \n",
    "    # 返回一个最佳分割特征与最佳分割点，注意会有空的情况\n",
    "    return best_f_idx,best_f_val\n",
    "\n",
    "# Test(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后就可以使用递归来生成树了。树中每一个节点需要保存的信息有：分割特征，分割点，以及左右分支。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cut_f': 5, 'cut_val': 6.833, 'left': {'cut_f': 12, 'cut_val': 14.37, 'left': {'cut_f': 12, 'cut_val': 4.85, 'left': {'cut_f': 6, 'cut_val': 21.8, 'left': 26.96, 'right': 32.82222222222222}, 'right': {'cut_f': 12, 'cut_val': 9.69, 'left': {'cut_f': 11, 'cut_val': 360.2, 'left': 31.560000000000002, 'right': {'cut_f': 5, 'cut_val': 6.122, 'left': {'cut_f': 6, 'cut_val': 56.8, 'left': {'cut_f': 5, 'cut_val': 5.927, 'left': 20.32857142857143, 'right': {'cut_f': 6, 'cut_val': 34.5, 'left': 22.46, 'right': 21.3}}, 'right': 19.085714285714285}, 'right': {'cut_f': 5, 'cut_val': 6.606, 'left': {'cut_f': 0, 'cut_val': 0.04684, 'left': {'cut_f': 1, 'cut_val': 0.0, 'left': 20.32, 'right': {'cut_f': 11, 'cut_val': 395.75, 'left': 23.114285714285717, 'right': 24.34}}, 'right': {'cut_f': 9, 'cut_val': 277.0, 'left': 27.0, 'right': {'cut_f': 5, 'cut_val': 6.487, 'left': {'cut_f': 5, 'cut_val': 6.376, 'left': {'cut_f': 11, 'cut_val': 393.39, 'left': 22.46666666666667, 'right': 23.740000000000002}, 'right': {'cut_f': 0, 'cut_val': 0.12757, 'left': 23.479999999999997, 'right': 24.55}}, 'right': 25.599999999999998}}}, 'right': {'cut_f': 10, 'cut_val': 17.4, 'left': 28.016666666666666, 'right': {'cut_f': 4, 'cut_val': 0.472, 'left': 26.619999999999997, 'right': 24.72}}}}}, 'right': {'cut_f': 2, 'cut_val': 4.05, 'left': 24.259999999999998, 'right': {'cut_f': 5, 'cut_val': 5.757, 'left': {'cut_f': 12, 'cut_val': 13.15, 'left': {'cut_f': 10, 'cut_val': 18.9, 'left': 16.419999999999998, 'right': 18.428571428571427}, 'right': 20.94}, 'right': {'cut_f': 6, 'cut_val': 81.6, 'left': {'cut_f': 2, 'cut_val': 5.86, 'left': 19.8125, 'right': {'cut_f': 5, 'cut_val': 5.871, 'left': 20.433333333333334, 'right': {'cut_f': 4, 'cut_val': 0.464, 'left': 21.04, 'right': {'cut_f': 4, 'cut_val': 0.507, 'left': 23.92, 'right': {'cut_f': 4, 'cut_val': 0.544, 'left': 22.0, 'right': 22.933333333333334}}}}}, 'right': {'cut_f': 0, 'cut_val': 1.35472, 'left': {'cut_f': 0, 'cut_val': 0.1396, 'left': 19.933333333333334, 'right': 18.72222222222222}, 'right': 21.214285714285715}}}}}}, 'right': {'cut_f': 0, 'cut_val': 5.69175, 'left': {'cut_f': 0, 'cut_val': 0.17899, 'left': {'cut_f': 10, 'cut_val': 19.1, 'left': {'cut_f': 4, 'cut_val': 0.524, 'left': 22.133333333333336, 'right': 20.52}, 'right': 18.46666666666667}, 'right': {'cut_f': 6, 'cut_val': 79.8, 'left': 20.2, 'right': {'cut_f': 4, 'cut_val': 0.52, 'left': 18.566666666666666, 'right': {'cut_f': 12, 'cut_val': 18.72, 'left': {'cut_f': 5, 'cut_val': 5.701, 'left': 14.459999999999999, 'right': {'cut_f': 0, 'cut_val': 0.55778, 'left': 17.82, 'right': {'cut_f': 5, 'cut_val': 5.99, 'left': 17.237499999999997, 'right': 15.777777777777779}}}, 'right': {'cut_f': 8, 'cut_val': 4.0, 'left': {'cut_f': 9, 'cut_val': 307.0, 'left': 13.866666666666667, 'right': 11.360000000000001}, 'right': {'cut_f': 7, 'cut_val': 1.4608, 'left': 13.84, 'right': 16.083333333333332}}}}}}, 'right': {'cut_f': 12, 'cut_val': 26.4, 'left': {'cut_f': 7, 'cut_val': 2.0635, 'left': {'cut_f': 4, 'cut_val': 0.614, 'left': 14.357142857142858, 'right': {'cut_f': 11, 'cut_val': 240.52, 'left': 9.7625, 'right': {'cut_f': 6, 'cut_val': 98.8, 'left': {'cut_f': 12, 'cut_val': 17.12, 'left': 13.779999999999998, 'right': 13.120000000000001}, 'right': 10.844444444444445}}}, 'right': {'cut_f': 11, 'cut_val': 318.01, 'left': 13.933333333333334, 'right': 16.7}}, 'right': {'cut_f': 5, 'cut_val': 4.906, 'left': 10.683333333333332, 'right': {'cut_f': 11, 'cut_val': 329.46, 'left': 8.639999999999999, 'right': 6.3}}}}}, 'right': {'cut_f': 5, 'cut_val': 7.416, 'left': {'cut_f': 12, 'cut_val': 11.66, 'left': {'cut_f': 7, 'cut_val': 2.0107, 'left': 38.78, 'right': {'cut_f': 6, 'cut_val': 62.5, 'left': {'cut_f': 4, 'cut_val': 0.433, 'left': {'cut_f': 5, 'cut_val': 7.088, 'left': 31.21666666666667, 'right': 34.099999999999994}, 'right': {'cut_f': 8, 'cut_val': 4.0, 'left': 34.199999999999996, 'right': 35.96}}, 'right': {'cut_f': 5, 'cut_val': 7.079, 'left': 27.619999999999997, 'right': 31.920000000000005}}}, 'right': 20.28}, 'right': {'cut_f': 10, 'cut_val': 14.9, 'left': {'cut_f': 5, 'cut_val': 7.82, 'left': 46.333333333333336, 'right': 49.6625}, 'right': {'cut_f': 6, 'cut_val': 53.6, 'left': 43.75, 'right': 37.160000000000004}}}}\n"
     ]
    }
   ],
   "source": [
    "def CART(data,criteria='mse',min_samples_split=5,min_samples_leaf=5,min_impurity_decrease=0.0):\n",
    "    # 首先是做test，数据集的质量由Test函数来保证并提供反馈\n",
    "    best_f_idx,best_f_val=Test(data)\n",
    "    \n",
    "    tree={}\n",
    "    tree['cut_f']=best_f_idx\n",
    "    tree['cut_val']=best_f_val\n",
    "    \n",
    "    if best_f_idx==None:    # f_idx为空表示需要生成叶节点\n",
    "        return best_f_val\n",
    "        \n",
    "    data_left,data_right=BinSplitData(data,best_f_idx,best_f_val)\n",
    "    tree['left']=CART(data_left)\n",
    "    tree['right']=CART(data_right)\n",
    "    \n",
    "    return tree\n",
    "\n",
    "tree=CART(training_data)\n",
    "# print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:25.022801722741566\n"
     ]
    }
   ],
   "source": [
    "def predict_one(x_test, tree, default=-1):\n",
    "    if isinstance(tree, dict):    # 非叶节点才做左右判断\n",
    "        cut_f_idx, cut_val = tree['cut_f'], tree['cut_val']\n",
    "        sub_tree = tree['left'] if x_test[cut_f_idx] <= cut_val else tree['right']\n",
    "        return predict_one(x_test, sub_tree)\n",
    "    else:    # 叶节点则直接返回值\n",
    "        return tree\n",
    "    \n",
    "# test_idx=100\n",
    "# print(predict_one(X_test[test_idx],tree),Y_test[test_idx])\n",
    "    \n",
    "def predict(X_test,tree):\n",
    "    return [predict_one(x_test,tree) for x_test in X_test]\n",
    "    \n",
    "Y_pred=predict(X_test,tree)\n",
    "print('MSE:{}'.format(np.mean(np.square(Y_pred-Y_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用sklearn中的回归树来做效果对比。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:26.058761526663137\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt_reg=DecisionTreeRegressor(min_samples_split=5, min_samples_leaf=5)\n",
    "dt_reg.fit(X_train,Y_train)\n",
    "Y_pred=dt_reg.predict(X_test)\n",
    "print('MSE:{}'.format(np.mean(np.square(Y_pred-Y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
