{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dataset = np.array([[1, 3, 4],\n",
    "                    [2, 3, 5],\n",
    "                    [1, 2, 3, 5],\n",
    "                    [2, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_1st_itemset(dataset):\n",
    "    '''\n",
    "    根据初始数据集创建单个物品的项集\n",
    "    '''\n",
    "#     tmp=dataset.flatten(dataset)    # 当输入数据规整时可使用numpy\n",
    "#     return np.unique(tmp)\n",
    "    tmp = list()\n",
    "    for itemset in dataset:\n",
    "        for item in itemset:\n",
    "            if [item] not in tmp:\n",
    "                tmp.append([item])\n",
    "    tmp.sort()\n",
    "    return list(map(frozenset, tmp))    # frozenset可用作字典key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def itemset_filter(dataset, itemsets, min_sup=0.5):\n",
    "    '''\n",
    "    过滤小于支持度阈值的项集，返回频繁项集\n",
    "    '''\n",
    "    sup_dict = dict()    # 支持度字典\n",
    "\n",
    "    # 先计数\n",
    "    for itemset in dataset:\n",
    "        for item in itemsets:\n",
    "            if item.issubset(itemset):\n",
    "                sup_dict[item] = sup_dict.get(item, 0)+1\n",
    "\n",
    "    len_data = len(dataset)    # 计数/总数=支持度\n",
    "    freq_sets = list()\n",
    "    for itemset in sup_dict:\n",
    "        sup = sup_dict[itemset]/len_data\n",
    "        if sup >= min_sup:\n",
    "            freq_sets.append(itemset)\n",
    "        sup_dict[itemset] = sup\n",
    "\n",
    "    return freq_sets, sup_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_itemset(freq_sets):\n",
    "    '''\n",
    "    根据已有的频繁项集生成高阶项集\n",
    "    '''\n",
    "    res = list()\n",
    "    raw_size = len(freq_sets)\n",
    "\n",
    "    for i in range(raw_size):\n",
    "        for j in range(i+1, raw_size):    # 两两组合\n",
    "            # 当两项集头部都相等时，可以进行合并\n",
    "            head_1 = list(freq_sets[i])[:-1]\n",
    "            head_2 = list(freq_sets[j])[:-1]\n",
    "            if head_1 == head_2:\n",
    "                res.append(freq_sets[i] | freq_sets[j])\n",
    "    return res\n",
    "\n",
    "\n",
    "# itemsets_1st= create_1st_itemset(dataset)\n",
    "# freq_sets_1st,_=itemset_filter(dataset, itemsets_1st, 0.5)\n",
    "# itemsets_2nd = extend_itemset(freq_sets_1st)\n",
    "# freq_sets_2nd, _ = itemset_filter(dataset, itemsets_2nd, 0.5)\n",
    "# itemsets_3th = extend_itemset(freq_sets_2nd)\n",
    "# freq_sets_3th, _ = itemset_filter(dataset, itemsets_3th, 0.5)\n",
    "# freq_sets_3th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[],\n",
       "  [frozenset({1}), frozenset({3}), frozenset({2}), frozenset({5})],\n",
       "  [frozenset({1, 3}), frozenset({2, 3}), frozenset({3, 5}), frozenset({2, 5})],\n",
       "  [frozenset({2, 3, 5})],\n",
       "  []],\n",
       " {frozenset({1}): 0.5,\n",
       "  frozenset({3}): 0.75,\n",
       "  frozenset({4}): 0.25,\n",
       "  frozenset({2}): 0.75,\n",
       "  frozenset({5}): 0.75,\n",
       "  frozenset({1, 3}): 0.5,\n",
       "  frozenset({2, 3}): 0.5,\n",
       "  frozenset({3, 5}): 0.5,\n",
       "  frozenset({2, 5}): 0.75,\n",
       "  frozenset({1, 2}): 0.25,\n",
       "  frozenset({1, 5}): 0.25,\n",
       "  frozenset({2, 3, 5}): 0.5})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apriori(dataset, min_sup=0.5):\n",
    "    itemsets_1st = create_1st_itemset(dataset)\n",
    "    freq_sets_1st, sup_dict = itemset_filter(dataset, itemsets_1st, min_sup)\n",
    "    freq_sets = [[], freq_sets_1st]\n",
    "\n",
    "    while len(freq_sets[-1]) > 0:\n",
    "        cur_itemsets = extend_itemset(freq_sets[-1])\n",
    "        cur_freq_sets, cur_sup_dict = itemset_filter(\n",
    "            dataset, cur_itemsets, min_sup)\n",
    "        sup_dict.update(cur_sup_dict)\n",
    "        freq_sets.append(cur_freq_sets)\n",
    "\n",
    "    return freq_sets, sup_dict\n",
    "\n",
    "\n",
    "apriori(dataset)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
