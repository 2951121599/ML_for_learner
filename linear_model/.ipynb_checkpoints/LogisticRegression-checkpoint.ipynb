{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=load_breast_cancer()\n",
    "X=data.data\n",
    "Y=data.target\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据$X$是一个$(n{\\times}m)$的矩阵，每一行是一个样本，每一列代表一个特征："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=X_train.shape[0]\n",
    "m=X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标签$Y$是一个列向量，其行数与$X$相同："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.reshape((n, 1))\n",
    "Y_test = Y_test.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 粗略模型\n",
    "\n",
    "模型表达式为：\n",
    "$$\n",
    "\\hat{Y}=\\sigma{(XW^{T}+b)}\n",
    "$$\n",
    "其中\n",
    "$$\n",
    "\\sigma(x)=\\frac{1}{1+e^{-x}}\n",
    "$$\n",
    "权重系数$W$的形状为$(1,m)$，偏置系数$b$为单变量系数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意这里有一个计算精度问题。在实际中，sigmoid函数只有在正负无穷处才能取到1或0，\n",
    "# 而在计算机中因为精度问题，在值稍大或稍小时即会使sigmoid函数取到1或0，需要对这种情况做处理。\n",
    "def sigmoid(x):\n",
    "    epsilon=1e-8\n",
    "    val=1/(1+np.exp(-x))\n",
    "    \n",
    "    ones_index=np.where(val>1-epsilon)\n",
    "    val[ones_index]=1-epsilon\n",
    "    \n",
    "    zeros_index=np.where(val<epsilon)\n",
    "    val[zeros_index]=epsilon\n",
    "    \n",
    "    return val\n",
    "\n",
    "W = np.random.rand(m).reshape((1, -1))  # 权重，行向量\n",
    "b = np.ones((1, 1))  # 偏置\n",
    "\n",
    "Y_hat=np.dot(X_train, W.T)+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型的损失函数为：\n",
    "$$\n",
    "\\begin{align}\n",
    "L&=-\\sum\\limits_{i=1}^n[y^{(i)}\\ln{y^{(i)}}+(1-y^{(i)})\\ln{(1-y^{(i)})}] \\\\\n",
    "&=-\\frac{1}{n}[Y^{T}\\ln{\\hat{Y}}+(1-Y)^{T}\\ln{(1-\\hat{Y})}] \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "损失函数关于参数$W$与$b$的梯度可以求得：\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial{L}}{\\partial{W}}&=\\frac{1}{n}(\\hat{Y}-Y)^{T}{\\cdot}X \\\\\n",
    "\\frac{\\partial{L}}{\\partial{b}}&=\\frac{1}{n}(\\hat{Y}-Y)^{T}{\\cdot}[1,1,...,1]^{T} \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dW = (Y_hat - Y_train).T.dot(X_train) / n\n",
    "db = (Y_hat - Y_train).T.dot(np.ones((n, 1))) / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参数的迭代更新公式：\n",
    "$$\n",
    "W:=W-{\\alpha}\\frac{\\partial{L}}{\\partial{W}}, \\quad b:b-{\\alpha}\\frac{\\partial{L}}{\\partial{b}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter=1000\n",
    "alpha=0.000001        # 注意学习率过大会导致震荡，然后误差越来越大\n",
    "\n",
    "for i in range(max_iter+1):\n",
    "    Y_hat=sigmoid(np.dot(X_train, W.T)+b)\n",
    "    \n",
    "    dW = (Y_hat - Y_train).T.dot(X_train) / n\n",
    "    db = (Y_hat - Y_train).T.dot(np.ones((n, 1))) / n\n",
    "    \n",
    "    W = W - alpha * dW\n",
    "    b = b - alpha * db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用该模型分别对训练集与预测集做预测："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=0.5\n",
    "Y_pred_train=np.where(sigmoid(np.dot(X_train, W.T)+b)>threshold,1,0)\n",
    "Y_pred_test=np.where(sigmoid(np.dot(X_test, W.T)+b)>threshold,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义一个Precision函数来评价模型的表现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7098901098901099 0.7631578947368421\n"
     ]
    }
   ],
   "source": [
    "def ACC(Y_true,Y_pred):\n",
    "    return np.sum(Y_true==Y_pred)/Y_true.shape[0]\n",
    "\n",
    "print(ACC(Y_train,Y_pred_train),ACC(Y_test,Y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型简单打包："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3223.6191321123324 3223.6191321123324 3223.6191321123324 3223.6191321123324 3223.6191321123324 3181.3082791878833 2186.2648280676976 914.9527068357011 705.9708180021119 678.5474657340123 649.2502241361556 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\qq435\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "def logit_reg(X,Y,alpha=0.000001,max_iter=2000,threshold=0.5):\n",
    "    n=X.shape[0]\n",
    "    m=X.shape[1]\n",
    "    \n",
    "    W = np.random.rand(m).reshape((1, -1))  # 权重，行向量\n",
    "    b = np.ones((1, 1))  # 偏置\n",
    "#     epsilon=1e-10        # 因计算精度问题，在做ln运算时加上这个极小值\n",
    "\n",
    "    for i in range(max_iter+1):\n",
    "        Y_hat=sigmoid(np.dot(X_train, W.T)+b)\n",
    "\n",
    "        dW = (Y_hat - Y).T.dot(X) / n\n",
    "        db = (Y_hat - Y).T.dot(np.ones((n, 1))) / n\n",
    "\n",
    "        W = W - alpha * dW\n",
    "        b = b - alpha * db\n",
    "\n",
    "        if i%200==0:\n",
    "            Y_hat=sigmoid(np.dot(X_train, W.T)+b)\n",
    "            L=np.sum(-np.dot(Y.T,np.log(Y_hat))-np.dot((1-Y).T,np.log(1-Y_hat)))\n",
    "            print(L,end=' ')\n",
    "\n",
    "    return W,b\n",
    "\n",
    "W,b=logit_reg(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据归一化\n",
    "**Normalization：**\n",
    "$$\n",
    "x=\\frac{x-x_{min}}{x_{max}-x_{min}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.row_stack((X_train,X_test))\n",
    "\n",
    "X_max=X.max(axis=0)\n",
    "X_min=X.min(axis=0)\n",
    "\n",
    "X_train_norm=(X_train-X_min)/(X_max-X_min)\n",
    "X_test_norm=(X_test-X_min)/(X_max-X_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对数据归一化之后再测试模型表现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3223.6191321123324 3223.6191321123324 3223.6191321123324 3223.6191321123324 3223.6191321123324 3223.6191321123324 3223.6191321123324 3223.6191321123324 3223.6191321123324 3223.6191321123324 3223.6191321123324 "
     ]
    }
   ],
   "source": [
    "W,b=logit_reg(X_train_norm,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为数据做了归一化，整个数据集上的梯度分布得到了改良，所以可以调大学习率，由此可以看出数据标准化在logistic regression上的威力："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3223.6191321123324 1061.4825061220477 141.96491849822374 62.43757154310592 56.70962883830205 53.534686901478565 51.140023280276885 49.20319119624459 47.570556619499115 46.15747225749712 44.9126731507272 "
     ]
    }
   ],
   "source": [
    "W,b=logit_reg(X_train_norm,Y_train,alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standardization：**\n",
    "$$\n",
    "x=\\frac{x-x_{\\mu}}{\\sigma}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.row_stack((X_train,X_test))\n",
    "\n",
    "X_avg=X.mean(axis=0)\n",
    "X_std=X.std(axis=0)\n",
    "\n",
    "X_train_std=(X_train-X_avg)/X_std\n",
    "X_test_std=(X_test-X_avg)/X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3223.6191321123324 3223.6191321123324 3223.6191321123324 3223.6191321123324 3223.6191321123324 3223.6191321123324 3223.6191321123324 3223.6191321123324 3223.6191321123324 3223.6191321123324 3223.6191321123324 "
     ]
    }
   ],
   "source": [
    "W,b=logit_reg(X_train_std,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3223.6191321123324 3223.6191321123324 3223.6191321123324 3223.6191321123324 3181.350301464521 1337.6074968055227 919.0454196438369 778.6788065482548 724.2800249855735 698.1279193400684 675.5638209393013 "
     ]
    }
   ],
   "source": [
    "W,b=logit_reg(X_train_std,Y_train,alpha=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初步观察，在logistic regression中好像有负数就不太行的样子，后续待补充。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.row_stack((X_train,X_test))\n",
    "\n",
    "X_max=X.max(axis=0)\n",
    "X_min=X.min(axis=0)\n",
    "X_avg=X.mean(axis=0)\n",
    "\n",
    "X_train_norm=(X_train-X_avg)/(X_max-X_min)\n",
    "X_test_norm=(X_test-X_avg)/(X_max-X_min)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
